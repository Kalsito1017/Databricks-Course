{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dbd0f56-7635-4390-9a98-0735ae349d82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/Workspace/Users/Databricks-Course/customer.csv\", inferSchema=True, header=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38759935-a61e-4ae1-95df-7e9d85a821f3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create temporary views in Databricks"
    }
   },
   "outputs": [],
   "source": [
    "df.createTempView(\"customer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa502dd6-6b21-4325-956c-3d6dd46c0e5b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create temporary views in Databricks"
    }
   },
   "outputs": [],
   "source": [
    "df1 = spark.sql(\"select * from customer\")\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbddcf51-854e-4689-8e47-ab2c53bfb372",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create temporary views in Databricks"
    }
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"customer_new\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6698a28-5ddf-4c0e-8766-e87cb4fe41d2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create temporary views in Databricks"
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(\"show views\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6f786ad-b5fb-486d-8c58-39b66dd3d3b5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create temporary views in Databricks"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"drop view customer_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "611eafce-f42c-43c2-9e41-d725878f576b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create temporary views in Databricks"
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(\"show views\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "249bbf9d-bd48-449d-ac04-3d92954534ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.createGlobalTempView(\"customer_global\")\n",
    "#[NOT_SUPPORTED_WITH_SERVERLESS] GLOBAL TEMPORARY VIEW is not supported on serverless compute. SQLSTATE: 0A000\n",
    "display(spark.sql(\"select * from global_temp.customer_global\"))\n",
    "\n",
    "df.createOrReplaceGlobalTempView(\"customer_new_global\")\n",
    "display(spark.sql(\"show views in global_temp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "023efe00-f66b-41e5-85de-86c91ce33f7e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Use Spark SQL transformations"
    }
   },
   "outputs": [],
   "source": [
    "df1 = spark.sql(\"select customer_id, name, email, customer_type from customer\")\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7eb1e563-7780-4078-84f6-177fae45d7f5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Use Spark SQL transformations"
    }
   },
   "outputs": [],
   "source": [
    "df2 = spark.sql(\"select * from customer where customer_type = 'Regular'\")\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e707ce00-c13a-4f18-b65f-ea10ab7a877e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Use Spark SQL transformations"
    }
   },
   "outputs": [],
   "source": [
    "df2 = spark.sql(\"select * from customer where customer_type = 'Regular' and country = 'UK'\")\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c19a1acf-0cf0-4a3a-a2cc-110de4215b1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Group by customer_type, count, and order by count descending\n",
    "df_group1 = spark.sql(\"\"\"\n",
    "    SELECT customer_type, COUNT(*) AS customer_count\n",
    "    FROM customer\n",
    "    GROUP BY customer_type\n",
    "    ORDER BY customer_count DESC\n",
    "\"\"\")\n",
    "display(df_group1)\n",
    "\n",
    "# 2. Group by country, count, and order by count descending\n",
    "df_group2 = spark.sql(\"\"\"\n",
    "    SELECT country, COUNT(*) AS country_count\n",
    "    FROM customer\n",
    "    GROUP BY country\n",
    "    ORDER BY country_count DESC\n",
    "\"\"\")\n",
    "display(df_group2)\n",
    "\n",
    "# 3. Group by customer_type and country, count, and order by count descending\n",
    "df_group3 = spark.sql(\"\"\"\n",
    "    SELECT customer_type, country, COUNT(*) AS type_country_count\n",
    "    FROM customer\n",
    "    GROUP BY customer_type, country\n",
    "    ORDER BY type_country_count DESC\n",
    "\"\"\")\n",
    "display(df_group3)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark-SQL",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
