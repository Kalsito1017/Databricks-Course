{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "63aa254a-d9b9-45cc-999a-cf2d57a702cd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Reading the csv file"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/Workspace/Users/Databricks-Course/customer.csv\", header=True, inferSchema=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6265e3c6-4ad2-453f-9b9c-4c84d533355d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Changing StructType"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import * \n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"customer_type\", StringType(), True),\n",
    "    StructField(\"registration_date\", DateType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"total_purchases\", IntegerType(), True),\n",
    "    StructField(\"ingestion_timestamp\", TimestampType(), True)\n",
    "])\n",
    "# Read the CSV file with the defined schema\n",
    "df1 = spark.read.csv(\"/Workspace/Users/Databricks-Course/customer.csv\", header=True, schema=schema)\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "06bb0858-9b1b-4971-b5ab-234d04905beb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Filtering function"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df1 = df.filter(col(\"customer_type\") == \"VIP\")\n",
    "df2 = df.where(\n",
    "    (col(\"Country\") == \"USA\") &\n",
    "    (col(\"customer_type\") == \"VIP\")\n",
    ")\n",
    "display(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4405ad50-c7f0-4989-8458-2533128726a1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Creating colums"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "df1 = df.withColumn(\"Salary\", col(\"age\")*100)\n",
    "df1.printSchema()\n",
    "display(df1)\n",
    "\n",
    "df2 = df.withColumn(\"Seniority\", when(df.age>30,'Senior').otherwise('Junior'))\n",
    "df2.printSchema()\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "265f83ce-09c2-4b20-b7b7-60a060872022",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Renaming created colums"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df2.withColumnRenamed(\"Seniority\", \"is_Senior\")\n",
    "#isplay(df3)\n",
    "df4 = df3.drop(\"is_Senior\")\n",
    "df5 = df3.drop(\"is_Senior\", \"age\", \"gender\")\n",
    "df5.printSchema()\n",
    "#display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "005c6b74-d40d-486e-aa5b-d563007c717b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Select function 1"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df.select(\"age\", \"gender\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3924311c-1117-49e0-901d-8c7f020ca319",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763725991943}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "Select functions 2"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df.select(\"age\", \"gender\", \"customer_type\")\n",
    "df2 = df.select(\"age\", \"gender\", \"customer_type\", col(\"age\")*1000)\n",
    "df3 = df.select(\"age\", \"gender\", \"customer_type\", (col(\"age\")*1000).alias(\"Salary\"))\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "87f46976-75fc-4d2f-ab92-31364954ef94",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Reading nested json?"
    }
   },
   "outputs": [],
   "source": [
    "df1 = spark.read.json(\"/Workspace/Users/Databricks-Course/SampleNested.json\")\n",
    "df2 = df1.select(\"address.city\", \"address.state\", \"age\", \"name\", \"email\")\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4126d345-eb1b-4b5a-ba4b-f067835414a0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Union and Distinct functions"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df.filter(\"customer_type == 'VIP'\")\n",
    "df2 = df.filter(\"customer_type == 'VIP'\").filter(\"age > 30\")\n",
    "df3 = df.filter(\"customer_type == 'VIP'\")\n",
    "df4 = df.union(df2).union(df)\n",
    "df5 = df4.distinct()\n",
    "df6 = df4.select(\"customer_type\",\"country\").distinct()\n",
    "display(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "16c0eca9-ec5b-4e58-8aef-ecdb014c4d3f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Handling nulls in PySpark"
    }
   },
   "outputs": [],
   "source": [
    "print(df.count())\n",
    "df1 = df.na.drop()\n",
    "print(df1.count())\n",
    "\n",
    "df2 = df1.filter(col(\"email\").isNull())\n",
    "#display(df2)\n",
    "\n",
    "df3 = df.na.fill(\"Unknown\")\n",
    "#display(df3)\n",
    "df4 = df.na.fill({\"email\": \"Unknown\", \"age\": 0})\n",
    "df5 = df.fillna({\"email\": \"Unknown\", \"age\": 0})\n",
    "df6 = df.dropna()\n",
    "\n",
    "display(df6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "cefc75b1-6368-4cb1-989b-a6023f3e77b5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Ordering data"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "df1 = df.orderBy(\"age\")\n",
    "df2 = df.orderBy(\"age\", \"gender\")\n",
    "df3 = df.orderBy(desc(\"age\"))\n",
    "df4 = df.orderBy(desc(\"age\"), \"gender\")\n",
    "df5 = df.sort(\"age\")\n",
    "df6 = df.sort(\"age\", \"gender\")\n",
    "df7 = df.sort(desc(\"age\"))\n",
    "df8 = df.sort(desc(\"age\"), \"gender\")\n",
    "df8 = df.orderBy(col(\"email\").asc_nulls_first())\n",
    "df9 = df.orderBy(col(\"email\").asc_nulls_last())\n",
    "df10 = df.orderBy(col(\"email\").desc_nulls_first())\n",
    "df11 = df.orderBy(col(\"email\").desc_nulls_last())\n",
    "display(df10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e3ef1c0-87e3-448a-ac7b-a126e7edca07",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Group By and sum avg max min functions"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, avg, max, min\n",
    "df1 = df.groupBy(\"gender\").count()\n",
    "df2 = df.groupBy(\"gender\", \"customer_type\").count()\n",
    "df3 = df.groupBy(\"gender\").sum(\"age\")\n",
    "df4 = df.groupBy(\"gender\").min(\"age\")\n",
    "df5 = df.groupBy(\"gender\").max(\"age\")\n",
    "df6 = df.groupBy(\"gender\").avg(\"age\")\n",
    "df7 = df.groupBy(\"gender\").agg(sum(\"age\"), max(\"age\"), min(\"age\"), avg(\"age\"))\n",
    "\n",
    "display(df7)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Reading customers.csv",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
